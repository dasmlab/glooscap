name: CI Pipeline

on:
  push:
    branches: ['**']  # All branches
  pull_request:
    branches: [main]
  workflow_dispatch:  # Manual trigger
    inputs:
      publish:
        description: 'Publish to GHCR'
        required: false
        default: 'false'
        type: boolean

env:
  REGISTRY: ghcr.io
  IMAGE_PREFIX: dasmlab

jobs:
  # Detect what changed to conditionally build components
  detect-changes:
    name: Detect Changes
    runs-on: ubuntu-latest
    outputs:
      operator: ${{ steps.filter.outputs.operator }}
      ui: ${{ steps.filter.outputs.ui }}
      translation-runner: ${{ steps.filter.outputs.translation-runner }}
      infra: ${{ steps.filter.outputs.infra }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 2  # Need history for change detection
      
      - uses: dorny/paths-filter@v3
        id: filter
        with:
          filters: |
            operator:
              - 'operator/**'
              - 'go.mod'
              - 'go.sum'
            ui:
              - 'ui/**'
            translation-runner:
              - 'translation-runner/**'
            infra:
              - 'infra/**'
              - '.github/workflows/**'

  # Build operator
  build-operator:
    name: Build Operator
    needs: detect-changes
    if: needs.detect-changes.outputs.operator == 'true' || github.event_name == 'workflow_dispatch'
    runs-on: self-hosted
    permissions:
      contents: read
      packages: write
    steps:
      - uses: actions/checkout@v4
      
      - name: Docker Diagnostics
        continue-on-error: true  # Don't fail the job if diagnostics have issues
        run: |
          set +e  # Disable exit on error
          set -uxo pipefail
          
          echo "== whoami / env =="
          id || true
          uname -a || true
          
          echo "== Fix Docker socket permissions =="
          # Get Docker socket GID dynamically
          DOCKER_GID=$(stat -c '%g' /var/run/docker.sock 2>/dev/null || echo "988")
          echo "Docker socket GID: $DOCKER_GID"
          
          # The socket GID might not match the docker group GID
          # We need to add runner to the group that matches the socket GID (988)
          # First, try to find/create a group with the socket's GID
          SOCKET_GROUP=$(getent group $DOCKER_GID 2>/dev/null | cut -d: -f1 || echo "")
          if [ -z "$SOCKET_GROUP" ]; then
            echo "No group found with GID $DOCKER_GID, creating 'dockersock'..."
            sudo groupadd -g $DOCKER_GID dockersock 2>/dev/null || {
              echo "⚠️ Failed to create group, trying to use existing docker group"
              SOCKET_GROUP="docker"
            }
            if [ -z "$SOCKET_GROUP" ] || [ "$SOCKET_GROUP" = "docker" ]; then
              SOCKET_GROUP="dockersock"
            fi
          else
            echo "Found group '$SOCKET_GROUP' with GID $DOCKER_GID"
          fi
          
          # Ensure SOCKET_GROUP is set
          if [ -z "$SOCKET_GROUP" ]; then
            echo "⚠️ Could not determine socket group, defaulting to 'docker'"
            SOCKET_GROUP="docker"
          fi
          echo "Using group: $SOCKET_GROUP"
          
          # Add runner user to the socket's group
          if ! id -nG | grep -qw "$SOCKET_GROUP"; then
            echo "Adding runner user to group $SOCKET_GROUP (GID: $DOCKER_GID)..."
            sudo usermod -aG $SOCKET_GROUP $(whoami) 2>/dev/null || sudo gpasswd -a $(whoami) $SOCKET_GROUP 2>/dev/null || true
          fi
          
          # Also add to docker group if it exists
          if getent group docker >/dev/null 2>&1; then
            if ! id -nG | grep -qw docker; then
              echo "Adding runner user to docker group..."
              sudo usermod -aG docker $(whoami) 2>/dev/null || sudo gpasswd -a $(whoami) docker 2>/dev/null || true
            fi
          fi
          
          # Use sg to activate group membership for this session
          echo "Current groups: $(id -nG)"
          echo "Activating group $SOCKET_GROUP..."
          
          echo "== docker daemon reachability =="
          ls -l /var/run/docker.sock || true
          
          # Try docker commands with group activation using sg
          sg $SOCKET_GROUP -c "docker version" 2>&1 || docker version || true
          sg $SOCKET_GROUP -c "docker info" 2>&1 || docker info || true
          
          echo "== buildx =="
          docker buildx version || true
          docker buildx ls || true
          
          echo "== builder containers =="
          docker ps -a --format 'table {{.Names}}\t{{.Image}}\t{{.Status}}' | sed -n '1,40p' || true
          
          echo "== cgroups (common DinD/buildkit failure) =="
          mount | grep -E 'cgroup|fuse-overlayfs|overlay' || true
          ls -l /sys/fs/cgroup || true
      
      # Skip docker/setup-buildx-action - it tries to create docker-container builder which fails
      # We'll create our own builder with docker driver (simpler, native builds)
      
      - name: Create and use buildx builder
        run: |
          # Get socket group for sg commands
          SOCKET_GID=$(stat -c '%g' /var/run/docker.sock 2>/dev/null || echo "988")
          SOCKET_GROUP=$(getent group $SOCKET_GID 2>/dev/null | cut -d: -f1 || echo "dockersock")
          
          # For now, use simple docker driver (native amd64 only)
          # This avoids BuildKit container permission issues
          # We'll add multi-arch later when ARM64 runner is ready
          echo "Setting up buildx for native amd64 builds..."
          
          # Remove existing builder if it exists
          sg $SOCKET_GROUP -c "docker buildx rm ci-builder" 2>/dev/null || true
          
          # Create builder with docker driver (simple, native platform only)
          sg $SOCKET_GROUP -c "docker buildx create --name ci-builder --driver docker --use" || {
            echo "⚠️ Failed to create builder, trying default..."
            sg $SOCKET_GROUP -c "docker buildx use default" || true
          }
          
          # Verify builder
          echo "Builder status:"
          sg $SOCKET_GROUP -c "docker buildx ls" || docker buildx ls || true
          sg $SOCKET_GROUP -c "docker buildx inspect ci-builder" || sg $SOCKET_GROUP -c "docker buildx inspect default" || true
      
      - name: Log in to GHCR
        run: |
          # Get socket group from env
          SOCKET_GROUP=${SOCKET_GROUP:-dockersock}
          
          # Login to GHCR using sg to ensure permissions
          echo "${{ secrets.GITHUB_TOKEN }}" | sg $SOCKET_GROUP -c "docker login ${{ env.REGISTRY }} -u ${{ github.actor }} --password-stdin" || {
            echo "❌ Login failed"
            exit 1
          }
          echo "✅ Logged in to ${{ env.REGISTRY }}"
      
      - name: Verify build context
        run: |
          echo "== Build context verification =="
          pwd
          ls -la
          git rev-parse --show-toplevel || true
          echo "== Operator directory =="
          ls -la ./operator/ || true
          test -f ./operator/Dockerfile && echo "✅ Dockerfile found" || echo "❌ Dockerfile missing"
      
      - name: Build and push operator
        run: |
          # Get socket group from env
          SOCKET_GROUP=${SOCKET_GROUP:-dockersock}
          
          # Generate image tag
          BRANCH_NAME="${{ github.ref_name }}"
          if [ "$BRANCH_NAME" = "main" ]; then
            IMAGE_TAG="${{ env.REGISTRY }}/${{ env.IMAGE_PREFIX }}/glooscap-operator:main"
          else
            IMAGE_TAG="${{ env.REGISTRY }}/${{ env.IMAGE_PREFIX }}/glooscap-operator:dev-${{ github.sha }}"
          fi
          
          echo "Building operator image: $IMAGE_TAG"
          
          # Check if we can use sg, otherwise use docker directly
          if getent group $SOCKET_GROUP >/dev/null 2>&1 && id -nG | grep -qw "$SOCKET_GROUP"; then
            DOCKER_CMD="sg $SOCKET_GROUP -c"
          else
            echo "⚠️ Using docker directly (group $SOCKET_GROUP not available)"
            DOCKER_CMD=""
          fi
          
          # Build with docker (native, fast)
          if [ -n "$DOCKER_CMD" ]; then
            $DOCKER_CMD "cd ./operator && docker build -t $IMAGE_TAG -f Dockerfile ." || {
              echo "❌ Build failed"
              exit 1
            }
          else
            cd ./operator && docker build -t $IMAGE_TAG -f Dockerfile . || {
              echo "❌ Build failed"
              exit 1
            }
          fi
          echo "✅ Build successful"
          
          # Push if not a PR
          if [ "${{ github.event_name }}" != "pull_request" ]; then
            echo "Pushing image..."
            if [ -n "$DOCKER_CMD" ]; then
              $DOCKER_CMD "docker push $IMAGE_TAG" || {
                echo "❌ Push failed"
                exit 1
              }
            else
              docker push $IMAGE_TAG || {
                echo "❌ Push failed"
                exit 1
              }
            fi
            echo "✅ Image pushed: $IMAGE_TAG"
          else
            echo "Skipping push (PR build)"
          fi

  # Build UI
  build-ui:
    name: Build UI
    needs: detect-changes
    if: needs.detect-changes.outputs.ui == 'true' || github.event_name == 'workflow_dispatch'
    runs-on: self-hosted
    permissions:
      contents: read
      packages: write
    steps:
      - uses: actions/checkout@v4
      
      - name: Docker Diagnostics
        continue-on-error: true  # Don't fail the job if diagnostics have issues
        run: |
          set +e  # Disable exit on error
          set -uxo pipefail
          
          echo "== whoami / env =="
          id || true
          uname -a || true
          
          echo "== Fix Docker socket permissions =="
          # Get Docker socket GID dynamically
          DOCKER_GID=$(stat -c '%g' /var/run/docker.sock 2>/dev/null || echo "988")
          echo "Docker socket GID: $DOCKER_GID"
          
          # The socket GID might not match the docker group GID
          # We need to add runner to the group that matches the socket GID (988)
          # First, try to find/create a group with the socket's GID
          SOCKET_GROUP=$(getent group $DOCKER_GID 2>/dev/null | cut -d: -f1 || echo "")
          if [ -z "$SOCKET_GROUP" ]; then
            echo "No group found with GID $DOCKER_GID, creating 'dockersock'..."
            sudo groupadd -g $DOCKER_GID dockersock 2>/dev/null || {
              echo "⚠️ Failed to create group, trying to use existing docker group"
              SOCKET_GROUP="docker"
            }
            if [ -z "$SOCKET_GROUP" ] || [ "$SOCKET_GROUP" = "docker" ]; then
              SOCKET_GROUP="dockersock"
            fi
          else
            echo "Found group '$SOCKET_GROUP' with GID $DOCKER_GID"
          fi
          
          # Ensure SOCKET_GROUP is set
          if [ -z "$SOCKET_GROUP" ]; then
            echo "⚠️ Could not determine socket group, defaulting to 'docker'"
            SOCKET_GROUP="docker"
          fi
          echo "Using group: $SOCKET_GROUP"
          
          # Add runner user to the socket's group
          if ! id -nG | grep -qw "$SOCKET_GROUP"; then
            echo "Adding runner user to group $SOCKET_GROUP (GID: $DOCKER_GID)..."
            sudo usermod -aG $SOCKET_GROUP $(whoami) 2>/dev/null || sudo gpasswd -a $(whoami) $SOCKET_GROUP 2>/dev/null || true
          fi
          
          # Also add to docker group if it exists
          if getent group docker >/dev/null 2>&1; then
            if ! id -nG | grep -qw docker; then
              echo "Adding runner user to docker group..."
              sudo usermod -aG docker $(whoami) 2>/dev/null || sudo gpasswd -a $(whoami) docker 2>/dev/null || true
            fi
          fi
          
          # Use sg to activate group membership for this session
          echo "Current groups: $(id -nG)"
          echo "Activating group $SOCKET_GROUP..."
          
          echo "== docker daemon reachability =="
          ls -l /var/run/docker.sock || true
          
          # Try docker commands with group activation using sg
          sg $SOCKET_GROUP -c "docker version" 2>&1 || docker version || true
          sg $SOCKET_GROUP -c "docker info" 2>&1 || docker info || true
          
          echo "== buildx =="
          docker buildx version || true
          docker buildx ls || true
          
          echo "== builder containers =="
          docker ps -a --format 'table {{.Names}}\t{{.Image}}\t{{.Status}}' | sed -n '1,40p' || true
          
          echo "== cgroups (common DinD/buildkit failure) =="
          mount | grep -E 'cgroup|fuse-overlayfs|overlay' || true
          ls -l /sys/fs/cgroup || true
      
      # Skip docker/setup-buildx-action - it tries to create docker-container builder which fails
      # We'll create our own builder with docker driver (simpler, native builds)
      
      - name: Create and use buildx builder
        run: |
          # Get socket group for sg commands
          SOCKET_GID=$(stat -c '%g' /var/run/docker.sock 2>/dev/null || echo "988")
          SOCKET_GROUP=$(getent group $SOCKET_GID 2>/dev/null | cut -d: -f1 || echo "dockersock")
          
          # For now, use simple docker driver (native amd64 only)
          # This avoids BuildKit container permission issues
          # We'll add multi-arch later when ARM64 runner is ready
          echo "Setting up buildx for native amd64 builds..."
          
          # Remove existing builder if it exists
          sg $SOCKET_GROUP -c "docker buildx rm ci-builder" 2>/dev/null || true
          
          # Create builder with docker driver (simple, native platform only)
          sg $SOCKET_GROUP -c "docker buildx create --name ci-builder --driver docker --use" || {
            echo "⚠️ Failed to create builder, trying default..."
            sg $SOCKET_GROUP -c "docker buildx use default" || true
          }
          
          # Verify builder
          echo "Builder status:"
          sg $SOCKET_GROUP -c "docker buildx ls" || docker buildx ls || true
          sg $SOCKET_GROUP -c "docker buildx inspect ci-builder" || sg $SOCKET_GROUP -c "docker buildx inspect default" || true
      
      - name: Log in to GHCR
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_PREFIX }}/glooscap-ui
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=sha,prefix={{branch}}-
            type=raw,value=dev-${{ github.sha }}
      
      - name: Verify build context
        run: |
          echo "== UI directory =="
          ls -la ./ui/ || true
          test -f ./ui/Dockerfile && echo "✅ Dockerfile found" || echo "❌ Dockerfile missing"
      
      - name: Build and push UI
        uses: docker/build-push-action@v5
        with:
          context: ./ui
          file: ./ui/Dockerfile
          push: ${{ github.event_name != 'pull_request' }}
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          platforms: linux/amd64
          builder: ci-builder

  # Build translation-runner
  build-translation-runner:
    name: Build Translation Runner
    needs: detect-changes
    if: needs.detect-changes.outputs.translation-runner == 'true' || github.event_name == 'workflow_dispatch'
    runs-on: self-hosted
    permissions:
      contents: read
      packages: write
    steps:
      - uses: actions/checkout@v4
      
      - name: Docker Diagnostics
        continue-on-error: true  # Don't fail the job if diagnostics have issues
        run: |
          set +e  # Disable exit on error
          set -uxo pipefail
          
          echo "== whoami / env =="
          id || true
          uname -a || true
          
          echo "== Fix Docker socket permissions =="
          # Get Docker socket GID dynamically
          DOCKER_GID=$(stat -c '%g' /var/run/docker.sock 2>/dev/null || echo "988")
          echo "Docker socket GID: $DOCKER_GID"
          
          # The socket GID might not match the docker group GID
          # We need to add runner to the group that matches the socket GID (988)
          # First, try to find/create a group with the socket's GID
          SOCKET_GROUP=$(getent group $DOCKER_GID 2>/dev/null | cut -d: -f1 || echo "")
          if [ -z "$SOCKET_GROUP" ]; then
            echo "No group found with GID $DOCKER_GID, creating 'dockersock'..."
            sudo groupadd -g $DOCKER_GID dockersock 2>/dev/null || {
              echo "⚠️ Failed to create group, trying to use existing docker group"
              SOCKET_GROUP="docker"
            }
            if [ -z "$SOCKET_GROUP" ] || [ "$SOCKET_GROUP" = "docker" ]; then
              SOCKET_GROUP="dockersock"
            fi
          else
            echo "Found group '$SOCKET_GROUP' with GID $DOCKER_GID"
          fi
          
          # Ensure SOCKET_GROUP is set
          if [ -z "$SOCKET_GROUP" ]; then
            echo "⚠️ Could not determine socket group, defaulting to 'docker'"
            SOCKET_GROUP="docker"
          fi
          echo "Using group: $SOCKET_GROUP"
          
          # Add runner user to the socket's group
          if ! id -nG | grep -qw "$SOCKET_GROUP"; then
            echo "Adding runner user to group $SOCKET_GROUP (GID: $DOCKER_GID)..."
            sudo usermod -aG $SOCKET_GROUP $(whoami) 2>/dev/null || sudo gpasswd -a $(whoami) $SOCKET_GROUP 2>/dev/null || true
          fi
          
          # Also add to docker group if it exists
          if getent group docker >/dev/null 2>&1; then
            if ! id -nG | grep -qw docker; then
              echo "Adding runner user to docker group..."
              sudo usermod -aG docker $(whoami) 2>/dev/null || sudo gpasswd -a $(whoami) docker 2>/dev/null || true
            fi
          fi
          
          # Use sg to activate group membership for this session
          echo "Current groups: $(id -nG)"
          echo "Activating group $SOCKET_GROUP..."
          
          echo "== docker daemon reachability =="
          ls -l /var/run/docker.sock || true
          
          # Try docker commands with group activation using sg
          sg $SOCKET_GROUP -c "docker version" 2>&1 || docker version || true
          sg $SOCKET_GROUP -c "docker info" 2>&1 || docker info || true
          
          echo "== buildx =="
          docker buildx version || true
          docker buildx ls || true
          
          echo "== builder containers =="
          docker ps -a --format 'table {{.Names}}\t{{.Image}}\t{{.Status}}' | sed -n '1,40p' || true
          
          echo "== cgroups (common DinD/buildkit failure) =="
          mount | grep -E 'cgroup|fuse-overlayfs|overlay' || true
          ls -l /sys/fs/cgroup || true
      
      # Skip docker/setup-buildx-action - it tries to create docker-container builder which fails
      # We'll create our own builder with docker driver (simpler, native builds)
      
      - name: Create and use buildx builder
        run: |
          # Get socket group for sg commands
          SOCKET_GID=$(stat -c '%g' /var/run/docker.sock 2>/dev/null || echo "988")
          SOCKET_GROUP=$(getent group $SOCKET_GID 2>/dev/null | cut -d: -f1 || echo "dockersock")
          
          # For now, use simple docker driver (native amd64 only)
          # This avoids BuildKit container permission issues
          # We'll add multi-arch later when ARM64 runner is ready
          echo "Setting up buildx for native amd64 builds..."
          
          # Remove existing builder if it exists
          sg $SOCKET_GROUP -c "docker buildx rm ci-builder" 2>/dev/null || true
          
          # Create builder with docker driver (simple, native platform only)
          sg $SOCKET_GROUP -c "docker buildx create --name ci-builder --driver docker --use" || {
            echo "⚠️ Failed to create builder, trying default..."
            sg $SOCKET_GROUP -c "docker buildx use default" || true
          }
          
          # Verify builder
          echo "Builder status:"
          sg $SOCKET_GROUP -c "docker buildx ls" || docker buildx ls || true
          sg $SOCKET_GROUP -c "docker buildx inspect ci-builder" || sg $SOCKET_GROUP -c "docker buildx inspect default" || true
      
      - name: Log in to GHCR
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_PREFIX }}/glooscap-translation-runner
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=sha,prefix={{branch}}-
            type=raw,value=dev-${{ github.sha }}
      
      - name: Verify build context
        run: |
          echo "== Translation-runner directory =="
          ls -la ./translation-runner/ || true
          test -f ./translation-runner/Dockerfile && echo "✅ Dockerfile found" || echo "❌ Dockerfile missing"
      
      - name: Build and push translation-runner
        uses: docker/build-push-action@v5
        with:
          context: ./translation-runner
          file: ./translation-runner/Dockerfile
          push: ${{ github.event_name != 'pull_request' }}
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          platforms: linux/amd64
          builder: ci-builder

  # Container scanning (DAST)
  scan-containers:
    name: Scan Containers
    needs: [build-operator, build-ui, build-translation-runner]
    if: always() && (needs.build-operator.result == 'success' || needs.build-ui.result == 'success' || needs.build-translation-runner.result == 'success')
    runs-on: self-hosted
    permissions:
      contents: read
      security-events: write
    strategy:
      fail-fast: false
      matrix:
        image:
          - name: glooscap-operator
            tag: ${{ github.ref_name == 'main' && 'main' || format('dev-{0}', github.sha) }}
          - name: glooscap-ui
            tag: ${{ github.ref_name == 'main' && 'main' || format('dev-{0}', github.sha) }}
          - name: glooscap-translation-runner
            tag: ${{ github.ref_name == 'main' && 'main' || format('dev-{0}', github.sha) }}
    steps:
      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: ${{ env.REGISTRY }}/${{ env.IMAGE_PREFIX }}/${{ matrix.image.name }}:${{ matrix.image.tag }}
          format: 'sarif'
          output: 'trivy-results.sarif'
          severity: 'CRITICAL,HIGH'
          exit-code: '0'  # Don't fail, just log (permissive mode)
      
      - name: Upload Trivy results to GitHub Security
        uses: github/codeql-action/upload-sarif@v3
        if: always()
        with:
          sarif_file: 'trivy-results.sarif'
      
      - name: Log scan results
        if: always()
        run: |
          echo "## Security Scan Results for ${{ matrix.image.name }}" >> $GITHUB_STEP_SUMMARY
          echo "Image: ${{ env.REGISTRY }}/${{ env.IMAGE_PREFIX }}/${{ matrix.image.name }}:${{ matrix.image.tag }}" >> $GITHUB_STEP_SUMMARY
          echo "⚠️ Scan completed (permissive mode - failures logged but not blocking)" >> $GITHUB_STEP_SUMMARY

  # Smoke test - full install and health checks
  smoke-test:
    name: Smoke Test
    needs: [build-operator, build-ui, build-translation-runner, scan-containers]
    if: always() && (needs.build-operator.result == 'success' || needs.build-ui.result == 'success' || needs.build-translation-runner.result == 'success')
    runs-on: self-hosted
    steps:
      - uses: actions/checkout@v4
      
      - name: Docker Diagnostics
        continue-on-error: true  # Don't fail the job if diagnostics have issues
        run: |
          set +e  # Disable exit on error
          set -uxo pipefail
          
          echo "== whoami / env =="
          id || true
          uname -a || true
          
          echo "== Fix Docker socket permissions =="
          # Get Docker socket GID dynamically
          DOCKER_GID=$(stat -c '%g' /var/run/docker.sock 2>/dev/null || echo "988")
          echo "Docker socket GID: $DOCKER_GID"
          
          # The socket GID might not match the docker group GID
          # We need to add runner to the group that matches the socket GID (988)
          # First, try to find/create a group with the socket's GID
          SOCKET_GROUP=$(getent group $DOCKER_GID 2>/dev/null | cut -d: -f1 || echo "")
          if [ -z "$SOCKET_GROUP" ]; then
            echo "No group found with GID $DOCKER_GID, creating 'dockersock'..."
            sudo groupadd -g $DOCKER_GID dockersock 2>/dev/null || {
              echo "⚠️ Failed to create group, trying to use existing docker group"
              SOCKET_GROUP="docker"
            }
            if [ -z "$SOCKET_GROUP" ] || [ "$SOCKET_GROUP" = "docker" ]; then
              SOCKET_GROUP="dockersock"
            fi
          else
            echo "Found group '$SOCKET_GROUP' with GID $DOCKER_GID"
          fi
          
          # Ensure SOCKET_GROUP is set
          if [ -z "$SOCKET_GROUP" ]; then
            echo "⚠️ Could not determine socket group, defaulting to 'docker'"
            SOCKET_GROUP="docker"
          fi
          echo "Using group: $SOCKET_GROUP"
          
          # Add runner user to the socket's group
          if ! id -nG | grep -qw "$SOCKET_GROUP"; then
            echo "Adding runner user to group $SOCKET_GROUP (GID: $DOCKER_GID)..."
            sudo usermod -aG $SOCKET_GROUP $(whoami) 2>/dev/null || sudo gpasswd -a $(whoami) $SOCKET_GROUP 2>/dev/null || true
          fi
          
          # Also add to docker group if it exists
          if getent group docker >/dev/null 2>&1; then
            if ! id -nG | grep -qw docker; then
              echo "Adding runner user to docker group..."
              sudo usermod -aG docker $(whoami) 2>/dev/null || sudo gpasswd -a $(whoami) docker 2>/dev/null || true
            fi
          fi
          
          # Use sg to activate group membership for this session
          echo "Current groups: $(id -nG)"
          echo "Activating group $SOCKET_GROUP..."
          
          echo "== docker daemon reachability =="
          ls -l /var/run/docker.sock || true
          
          # Try docker commands with group activation using sg
          sg $SOCKET_GROUP -c "docker version" 2>&1 || docker version || true
          sg $SOCKET_GROUP -c "docker info" 2>&1 || docker info || true
          
          echo "== buildx =="
          docker buildx version || true
          docker buildx ls || true
          
          echo "== builder containers =="
          docker ps -a --format 'table {{.Names}}\t{{.Image}}\t{{.Status}}' | sed -n '1,40p' || true
          
          echo "== cgroups (common DinD/buildkit failure) =="
          mount | grep -E 'cgroup|fuse-overlayfs|overlay' || true
          ls -l /sys/fs/cgroup || true
      
      # Skip docker/setup-buildx-action - it tries to create docker-container builder which fails
      # We'll create our own builder with docker driver (simpler, native builds)
      
      - name: Create and use buildx builder
        run: |
          # Get socket group for sg commands
          SOCKET_GID=$(stat -c '%g' /var/run/docker.sock 2>/dev/null || echo "988")
          SOCKET_GROUP=$(getent group $SOCKET_GID 2>/dev/null | cut -d: -f1 || echo "dockersock")
          
          # For now, use simple docker driver (native amd64 only)
          # This avoids BuildKit container permission issues
          # We'll add multi-arch later when ARM64 runner is ready
          echo "Setting up buildx for native amd64 builds..."
          
          # Remove existing builder if it exists
          sg $SOCKET_GROUP -c "docker buildx rm ci-builder" 2>/dev/null || true
          
          # Create builder with docker driver (simple, native platform only)
          sg $SOCKET_GROUP -c "docker buildx create --name ci-builder --driver docker --use" || {
            echo "⚠️ Failed to create builder, trying default..."
            sg $SOCKET_GROUP -c "docker buildx use default" || true
          }
          
          # Verify builder
          echo "Builder status:"
          sg $SOCKET_GROUP -c "docker buildx ls" || docker buildx ls || true
          sg $SOCKET_GROUP -c "docker buildx inspect ci-builder" || sg $SOCKET_GROUP -c "docker buildx inspect default" || true
      
      - name: Log in to GHCR
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Prepare test environment
        run: |
          # Ensure Docker is running (Docker-in-Docker)
          sudo systemctl start docker || true
          docker info
      
      - name: Run smoke test
        env:
          GLOOSCAP_VERSION: ${{ github.ref_name == 'main' && 'main' || format('dev-{0}', github.sha) }}
          ISKOCES_VERSION: ${{ github.ref_name == 'main' && 'main' || format('dev-{0}', github.sha) }}
        run: |
          cd infra/macos-foss
          chmod +x install_glooscap.sh
          
          # Run install with iskoces plugin
          ./install_glooscap.sh --plugins iskoces || {
            echo "❌ Smoke test failed"
            # Collect logs for debugging
            kubectl get pods -A || true
            kubectl logs -n glooscap-system deployment/operator-controller-manager --tail=100 || true
            kubectl logs -n iskoces deployment/iskoces-server --tail=100 || true
            exit 1
          }
      
      - name: Verify cluster health
        run: |
          # Wait for pods to be ready
          kubectl wait --for=condition=ready pod -l control-plane=controller-manager -n glooscap-system --timeout=300s || true
          kubectl wait --for=condition=ready pod -l app=iskoces-server -n iskoces --timeout=300s || true
          
          # Check pod status
          kubectl get pods -A
          
          # Health checks
          kubectl get pods -n glooscap-system -o jsonpath='{.items[*].status.phase}' | grep -q Running || {
            echo "❌ Operator pods not running"
            kubectl describe pods -n glooscap-system
            exit 1
          }
          
          # Check UI is accessible (if exposed)
          # curl -f http://localhost:3000/healthz || echo "UI health check skipped"
      
      - name: Cleanup test cluster
        if: always()
        run: |
          cd infra/macos-foss
          # Uninstall with auto-confirm (non-interactive)
          echo "y" | ./uninstall_glooscap.sh || true
          # Also try direct k3d/kubectl cleanup
          k3d cluster delete k3s-default || true
          docker stop $(docker ps -q) || true
          docker system prune -af || true

  # Code coverage (must not fail on syntax)
  coverage:
    name: Code Coverage
    runs-on: ubuntu-latest
    if: needs.detect-changes.outputs.operator == 'true' || github.event_name == 'workflow_dispatch'
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Go
        uses: actions/setup-go@v5
        with:
          go-version-file: operator/go.mod
      
      - name: Cache Go modules
        uses: actions/cache@v4
        with:
          path: ~/go/pkg/mod
          key: ${{ runner.os }}-go-${{ hashFiles('operator/go.sum') }}
      
      - name: Install dependencies
        working-directory: operator
        run: |
          go mod download
          go mod verify
      
      - name: Setup envtest
        working-directory: operator
        run: |
          make setup-envtest || echo "⚠️ envtest setup failed, continuing..."
      
      - name: Generate manifests
        working-directory: operator
        run: |
          make manifests generate || echo "⚠️ Manifest generation failed, continuing..."
      
      - name: Run tests with coverage
        working-directory: operator
        continue-on-error: true  # Don't fail on test failures
        run: |
          set +e  # Don't exit on error
          KUBEBUILDER_ASSETS="$(make -s setup-envtest 2>/dev/null | grep KUBEBUILDER_ASSETS | cut -d'=' -f2 | tr -d '"' || echo '')"
          if [ -n "$KUBEBUILDER_ASSETS" ]; then
            export KUBEBUILDER_ASSETS
            go test $(go list ./... 2>/dev/null | grep -v /e2e) \
              -coverprofile=coverage.out \
              -covermode=atomic \
              -v 2>&1 | tee test-output.txt || true
          else
            echo "⚠️ KUBEBUILDER_ASSETS not available, skipping tests"
            touch coverage.out
          fi
      
      - name: Generate coverage report
        if: always()
        working-directory: operator
        run: |
          if [ -f coverage.out ] && [ -s coverage.out ]; then
            go tool cover -html=coverage.out -o coverage.html || true
            go tool cover -func=coverage.out > coverage.txt || true
            echo "## Coverage Summary" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            tail -n 1 coverage.txt >> $GITHUB_STEP_SUMMARY || echo "No coverage data" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
          else
            echo "⚠️ No coverage data generated" >> $GITHUB_STEP_SUMMARY
          fi
      
      - name: Upload coverage
        if: always()
        uses: codecov/codecov-action@v4
        with:
          file: ./operator/coverage.out
          fail_ci_if_error: false  # Don't fail on coverage upload errors
          flags: unittests

  # Manual publish to GHCR (workflow_dispatch with input)
  publish-to-ghcr:
    name: Publish to GHCR
    needs: [build-operator, build-ui, build-translation-runner, smoke-test]
    if: github.event_name == 'workflow_dispatch' && github.event.inputs.publish == 'true'
    runs-on: self-hosted
    permissions:
      contents: read
      packages: write
    steps:
      - uses: actions/checkout@v4
      
      - name: Docker Diagnostics
        continue-on-error: true  # Don't fail the job if diagnostics have issues
        run: |
          set +e  # Disable exit on error
          set -uxo pipefail
          
          echo "== whoami / env =="
          id || true
          uname -a || true
          
          echo "== Fix Docker socket permissions =="
          # Get Docker socket GID dynamically
          DOCKER_GID=$(stat -c '%g' /var/run/docker.sock 2>/dev/null || echo "988")
          echo "Docker socket GID: $DOCKER_GID"
          
          # The socket GID might not match the docker group GID
          # We need to add runner to the group that matches the socket GID (988)
          # First, try to find/create a group with the socket's GID
          SOCKET_GROUP=$(getent group $DOCKER_GID 2>/dev/null | cut -d: -f1 || echo "")
          if [ -z "$SOCKET_GROUP" ]; then
            echo "No group found with GID $DOCKER_GID, creating 'dockersock'..."
            sudo groupadd -g $DOCKER_GID dockersock 2>/dev/null || {
              echo "⚠️ Failed to create group, trying to use existing docker group"
              SOCKET_GROUP="docker"
            }
            if [ -z "$SOCKET_GROUP" ] || [ "$SOCKET_GROUP" = "docker" ]; then
              SOCKET_GROUP="dockersock"
            fi
          else
            echo "Found group '$SOCKET_GROUP' with GID $DOCKER_GID"
          fi
          
          # Ensure SOCKET_GROUP is set
          if [ -z "$SOCKET_GROUP" ]; then
            echo "⚠️ Could not determine socket group, defaulting to 'docker'"
            SOCKET_GROUP="docker"
          fi
          echo "Using group: $SOCKET_GROUP"
          
          # Add runner user to the socket's group
          if ! id -nG | grep -qw "$SOCKET_GROUP"; then
            echo "Adding runner user to group $SOCKET_GROUP (GID: $DOCKER_GID)..."
            sudo usermod -aG $SOCKET_GROUP $(whoami) 2>/dev/null || sudo gpasswd -a $(whoami) $SOCKET_GROUP 2>/dev/null || true
          fi
          
          # Also add to docker group if it exists
          if getent group docker >/dev/null 2>&1; then
            if ! id -nG | grep -qw docker; then
              echo "Adding runner user to docker group..."
              sudo usermod -aG docker $(whoami) 2>/dev/null || sudo gpasswd -a $(whoami) docker 2>/dev/null || true
            fi
          fi
          
          # Use sg to activate group membership for this session
          echo "Current groups: $(id -nG)"
          echo "Activating group $SOCKET_GROUP..."
          
          echo "== docker daemon reachability =="
          ls -l /var/run/docker.sock || true
          
          # Try docker commands with group activation using sg
          sg $SOCKET_GROUP -c "docker version" 2>&1 || docker version || true
          sg $SOCKET_GROUP -c "docker info" 2>&1 || docker info || true
          
          echo "== buildx =="
          docker buildx version || true
          docker buildx ls || true
          
          echo "== builder containers =="
          docker ps -a --format 'table {{.Names}}\t{{.Image}}\t{{.Status}}' | sed -n '1,40p' || true
          
          echo "== cgroups (common DinD/buildkit failure) =="
          mount | grep -E 'cgroup|fuse-overlayfs|overlay' || true
          ls -l /sys/fs/cgroup || true
      
      # Skip docker/setup-buildx-action - it tries to create docker-container builder which fails
      # We'll create our own builder with docker driver (simpler, native builds)
      
      - name: Create and use buildx builder
        run: |
          # Get socket group for sg commands
          SOCKET_GID=$(stat -c '%g' /var/run/docker.sock 2>/dev/null || echo "988")
          SOCKET_GROUP=$(getent group $SOCKET_GID 2>/dev/null | cut -d: -f1 || echo "dockersock")
          
          # For now, use simple docker driver (native amd64 only)
          # This avoids BuildKit container permission issues
          # We'll add multi-arch later when ARM64 runner is ready
          echo "Setting up buildx for native amd64 builds..."
          
          # Remove existing builder if it exists
          sg $SOCKET_GROUP -c "docker buildx rm ci-builder" 2>/dev/null || true
          
          # Create builder with docker driver (simple, native platform only)
          sg $SOCKET_GROUP -c "docker buildx create --name ci-builder --driver docker --use" || {
            echo "⚠️ Failed to create builder, trying default..."
            sg $SOCKET_GROUP -c "docker buildx use default" || true
          }
          
          # Verify builder
          echo "Builder status:"
          sg $SOCKET_GROUP -c "docker buildx ls" || docker buildx ls || true
          sg $SOCKET_GROUP -c "docker buildx inspect ci-builder" || sg $SOCKET_GROUP -c "docker buildx inspect default" || true
      
      - name: Log in to GHCR
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Tag and push as dev-commitid
        run: |
          BRANCH_TAG="${{ github.ref_name }}"
          COMMIT_TAG="dev-${{ github.sha }}"
          
          # Retag and push all built images
          for image in glooscap-operator glooscap-ui glooscap-translation-runner; do
            docker pull ${{ env.REGISTRY }}/${{ env.IMAGE_PREFIX }}/$image:$BRANCH_TAG || true
            docker tag ${{ env.REGISTRY }}/${{ env.IMAGE_PREFIX }}/$image:$BRANCH_TAG \
                       ${{ env.REGISTRY }}/${{ env.IMAGE_PREFIX }}/$image:$COMMIT_TAG || true
            docker push ${{ env.REGISTRY }}/${{ env.IMAGE_PREFIX }}/$image:$COMMIT_TAG || true
          done
      
      - name: Cleanup old dev packages
        run: |
          # Keep only the 3 most recent dev-* packages per image
          for image in glooscap-operator glooscap-ui glooscap-translation-runner; do
            gh api \
              repos/${{ github.repository }}/packages/container/$image/versions \
              --jq '.[] | select(.metadata.container.tags[] | startswith("dev-")) | .id' \
              | tail -n +4 \
              | xargs -I {} gh api \
                repos/${{ github.repository }}/packages/container/$image/versions/{} \
                -X DELETE || true
          done

  # Main branch - system tests and publish as 'latest'
  system-tests:
    name: System Tests
    needs: [build-operator, build-ui, build-translation-runner, smoke-test]
    if: github.ref == 'refs/heads/main' && needs.smoke-test.result == 'success'
    runs-on: self-hosted
    steps:
      - uses: actions/checkout@v4
      
      - name: Run system test suite
        env:
          GLOOSCAP_VERSION: main
          ISKOCES_VERSION: main
        run: |
          # TODO: Add comprehensive system tests
          # - API endpoint tests
          # - Diagnostic job tests
          # - Translation job tests
          # - Wiki target connection tests
          echo "System tests placeholder - to be implemented"
      
      - name: Tag as latest
        if: success()
        run: |
          for image in glooscap-operator glooscap-ui glooscap-translation-runner; do
            docker pull ${{ env.REGISTRY }}/${{ env.IMAGE_PREFIX }}/$image:main || true
            docker tag ${{ env.REGISTRY }}/${{ env.IMAGE_PREFIX }}/$image:main \
                       ${{ env.REGISTRY }}/${{ env.IMAGE_PREFIX }}/$image:latest || true
            docker push ${{ env.REGISTRY }}/${{ env.IMAGE_PREFIX }}/$image:latest || true
          done

